{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c73ca1",
   "metadata": {},
   "source": [
    "### 🧠 What is Query Planning and Decomposition?\n",
    "Query Planning and Decomposition is a technique where a complex user query is broken down into simpler sub-questions or tasks, allowing a system (like a RAG agent) to:\n",
    "\n",
    "- Understand the question more deeply\n",
    "- Retrieve more precise and complete information\n",
    "- Execute step-by-step reasoning\n",
    "\n",
    "It's like reverse-engineering a question into manageable steps before answering.\n",
    "\n",
    "🧠 What's New in This Version?\n",
    "- ✅ Add a Query Planner Node\n",
    "- ✅ Break complex user queries into sub-questions\n",
    "- ✅ Retrieve docs per sub-question\n",
    "- ✅ Combine all retrieved contexts\n",
    "- ✅ Generate a final consolidated answer\n",
    "\n",
    "\n",
    "Example:\n",
    "Query: “Compare the GDP of India in 2020 with the population of India in 2020, and compute GDP per capita.”\n",
    "\n",
    "Query plan decomposition (explicit):\n",
    "\n",
    "Fetch GDP of India in 2020 (→ call World Bank API).\n",
    "\n",
    "Fetch population of India in 2020 (→ call Wikipedia/DB).\n",
    "\n",
    "Divide GDP / Population (→ use calculator tool).\n",
    "\n",
    "Return result as GDP per capita.\n",
    "\n",
    "Execution: Tools are invoked for each step, then results are combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b6a1663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader,WebBaseLoader\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e649ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "llm=init_chat_model(\"openai:gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da40f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 1. Load and Embed Documents\n",
    "# ----------------------------\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2024-04-12-diffusion-video/\"\n",
    "]\n",
    "docs = []\n",
    "for url in urls:\n",
    "    docs.extend(WebBaseLoader(url).load())\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(chunks, embedding)\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb30250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2. State Schema\n",
    "# ----------------------------\n",
    "class RAGState(BaseModel):\n",
    "    question: str\n",
    "    sub_questions: List[str] = []\n",
    "    retrieved_docs: List[Document] = []\n",
    "    answer: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff7d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3. Nodes\n",
    "# ----------------------------\n",
    "\n",
    "## a. Query Planner: splits input question\n",
    "def plan_query(state: RAGState) -> RAGState:\n",
    "   \n",
    "    prompt = f\"\"\"\n",
    "Break the following complex question into 2-3 sub-questions:\n",
    "\n",
    "Question: {state.question}\n",
    "\n",
    "Sub-questions:\n",
    "\"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    sub_questions = [line.strip(\"- \").strip() for line in result.content.strip().split(\"\\n\") if line.strip()]\n",
    "    return RAGState(question=state.question, sub_questions=sub_questions)\n",
    "\n",
    "## b. Retrieve documents for each sub-question\n",
    "def retrieve_for_each(state: RAGState) -> RAGState:\n",
    "    all_docs = []\n",
    "    for sub in state.sub_questions:\n",
    "        docs = retriever.invoke(sub)\n",
    "        all_docs.extend(docs)\n",
    "    return RAGState(question=state.question, sub_questions=state.sub_questions, retrieved_docs=all_docs)\n",
    "\n",
    "## c. Generate final answer\n",
    "def generate_final_answer(state: RAGState) -> RAGState:\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in state.retrieved_docs])\n",
    "    prompt = f\"\"\"\n",
    "Use the context below to answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {state.question}\n",
    "\"\"\"\n",
    "    \n",
    "    answer = llm.invoke(prompt).content\n",
    "    return RAGState(question=state.question, sub_questions=state.sub_questions, retrieved_docs=state.retrieved_docs, answer=answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7293a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x120d92180>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 4. Build LangGraph\n",
    "# ----------------------------\n",
    "builder = StateGraph(RAGState)\n",
    "\n",
    "builder.add_node(\"planner\", plan_query)\n",
    "builder.add_node(\"retriever\", retrieve_for_each)\n",
    "builder.add_node(\"responder\", generate_final_answer)\n",
    "\n",
    "builder.set_entry_point(\"planner\")\n",
    "builder.add_edge(\"planner\", \"retriever\")\n",
    "builder.add_edge(\"retriever\", \"responder\")\n",
    "builder.add_edge(\"responder\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcc27564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Explain how agent loops work and what are the challenges in diffusion video generation?', 'sub_questions': ['1. What are agent loops, and how do they function in video generation processes?', '2. What specific challenges are associated with diffusion methods in video generation?'], 'retrieved_docs': [Document(id='e7b5aac3-cdde-4d36-bc77-e36ad4cdbeab', metadata={'source': 'https://lilianweng.github.io/posts/2024-04-12-diffusion-video/', 'title': \"Diffusion Models for Video Generation | Lil'Log\", 'description': 'Diffusion models have demonstrated strong results on image synthesis in past years. Now the research community has started working on a harder task—using it for video generation. The task itself is a superset of the image case, since an image is a video of 1 frame, and it is much more challenging because:\\n\\nIt has extra requirements on temporal consistency across frames in time, which naturally demands more world knowledge to be encoded into the model.\\nIn comparison to text or images, it is more difficult to collect large amounts of high-quality, high-dimensional video data, let along text-video pairs.\\n\\n\\n\\n🥑 Required Pre-read: Please make sure you have read the previous blog on “What are Diffusion Models?” for image generation before continue here.\\n', 'language': 'en'}, page_content='In the case of video generation, we need the diffusion model to run multiple steps of upsampling for extending video length or increasing the frame rate. This requires the capability of sampling a second video $\\\\mathbf{x}^b$ conditioned on the first $\\\\mathbf{x}^a$, $\\\\mathbf{x}^b \\\\sim p_\\\\theta(\\\\mathbf{x}^b \\\\vert \\\\mathbf{x}^a)$, where $\\\\mathbf{x}^b$ might be an autoregressive extension of $\\\\mathbf{x}^a$ or be the missing frames in-between for a video $\\\\mathbf{x}^a$ at a low frame rate.'), Document(id='715fb3e3-36e7-489f-a72c-c78b867b3f02', metadata={'source': 'https://lilianweng.github.io/posts/2024-04-12-diffusion-video/', 'title': \"Diffusion Models for Video Generation | Lil'Log\", 'description': 'Diffusion models have demonstrated strong results on image synthesis in past years. Now the research community has started working on a harder task—using it for video generation. The task itself is a superset of the image case, since an image is a video of 1 frame, and it is much more challenging because:\\n\\nIt has extra requirements on temporal consistency across frames in time, which naturally demands more world knowledge to be encoded into the model.\\nIn comparison to text or images, it is more difficult to collect large amounts of high-quality, high-dimensional video data, let along text-video pairs.\\n\\n\\n\\n🥑 Required Pre-read: Please make sure you have read the previous blog on “What are Diffusion Models?” for image generation before continue here.\\n', 'language': 'en'}, page_content='Video Generation Modeling from Scratch#\\nFirst let’s review approaches for designing and training diffusion video models from scratch, meaning that we do not rely on pre-trained image generators.\\nParameterization & Sampling Basics#'), Document(id='d05da985-0471-433b-9927-e9348585ce93', metadata={'source': 'https://lilianweng.github.io/posts/2024-04-12-diffusion-video/', 'title': \"Diffusion Models for Video Generation | Lil'Log\", 'description': 'Diffusion models have demonstrated strong results on image synthesis in past years. Now the research community has started working on a harder task—using it for video generation. The task itself is a superset of the image case, since an image is a video of 1 frame, and it is much more challenging because:\\n\\nIt has extra requirements on temporal consistency across frames in time, which naturally demands more world knowledge to be encoded into the model.\\nIn comparison to text or images, it is more difficult to collect large amounts of high-quality, high-dimensional video data, let along text-video pairs.\\n\\n\\n\\n🥑 Required Pre-read: Please make sure you have read the previous blog on “What are Diffusion Models?” for image generation before continue here.\\n', 'language': 'en'}, page_content='Imagen Video (Ho, et al. 2022) is constructed on a cascade of diffusion models to enhance the video generation quality and upgrades to output 1280x768 videos at 24 fps. The Imagen Video architecture consists of the following components, counting 7 diffusion models in total.'), Document(id='5ed86f91-d322-4c10-b6f1-6b6c84b3b996', metadata={'source': 'https://lilianweng.github.io/posts/2024-04-12-diffusion-video/', 'title': \"Diffusion Models for Video Generation | Lil'Log\", 'description': 'Diffusion models have demonstrated strong results on image synthesis in past years. Now the research community has started working on a harder task—using it for video generation. The task itself is a superset of the image case, since an image is a video of 1 frame, and it is much more challenging because:\\n\\nIt has extra requirements on temporal consistency across frames in time, which naturally demands more world knowledge to be encoded into the model.\\nIn comparison to text or images, it is more difficult to collect large amounts of high-quality, high-dimensional video data, let along text-video pairs.\\n\\n\\n\\n🥑 Required Pre-read: Please make sure you have read the previous blog on “What are Diffusion Models?” for image generation before continue here.\\n', 'language': 'en'}, page_content='Imagen Video also applies progressive distillation to speed up sampling and each distillation iteration can reduce the required sampling steps by half. Their experiments were able to distill all 7 video diffusion models down to just 8 sampling steps per model without any noticeable loss in perceptual quality.'), Document(id='71adaf59-1289-49da-92bc-8b04de2fcabf', metadata={'source': 'https://lilianweng.github.io/posts/2024-04-12-diffusion-video/', 'title': \"Diffusion Models for Video Generation | Lil'Log\", 'description': 'Diffusion models have demonstrated strong results on image synthesis in past years. Now the research community has started working on a harder task—using it for video generation. The task itself is a superset of the image case, since an image is a video of 1 frame, and it is much more challenging because:\\n\\nIt has extra requirements on temporal consistency across frames in time, which naturally demands more world knowledge to be encoded into the model.\\nIn comparison to text or images, it is more difficult to collect large amounts of high-quality, high-dimensional video data, let along text-video pairs.\\n\\n\\n\\n🥑 Required Pre-read: Please make sure you have read the previous blog on “What are Diffusion Models?” for image generation before continue here.\\n', 'language': 'en'}, page_content='Adapting Image Models to Generate Videos\\n\\nFine-tuning on Video Data\\n\\nTraining-Free Adaptation\\n\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nDiffusion models have demonstrated strong results on image synthesis in past years. Now the research community has started working on a harder task—using it for video generation. The task itself is a superset of the image case, since an image is a video of 1 frame, and it is much more challenging because:'), Document(id='8d47612f-bed7-4a70-a89c-1b893b778da0', metadata={'source': 'https://lilianweng.github.io/posts/2024-04-12-diffusion-video/', 'title': \"Diffusion Models for Video Generation | Lil'Log\", 'description': 'Diffusion models have demonstrated strong results on image synthesis in past years. Now the research community has started working on a harder task—using it for video generation. The task itself is a superset of the image case, since an image is a video of 1 frame, and it is much more challenging because:\\n\\nIt has extra requirements on temporal consistency across frames in time, which naturally demands more world knowledge to be encoded into the model.\\nIn comparison to text or images, it is more difficult to collect large amounts of high-quality, high-dimensional video data, let along text-video pairs.\\n\\n\\n\\n🥑 Required Pre-read: Please make sure you have read the previous blog on “What are Diffusion Models?” for image generation before continue here.\\n', 'language': 'en'}, page_content='[12] Esser et al. 2023 “Structure and Content-Guided Video Synthesis with Diffusion Models.”\\n[13] Bar-Tal et al. 2024 “Lumiere: A Space-Time Diffusion Model for Video Generation.”'), Document(id='e7b5aac3-cdde-4d36-bc77-e36ad4cdbeab', metadata={'source': 'https://lilianweng.github.io/posts/2024-04-12-diffusion-video/', 'title': \"Diffusion Models for Video Generation | Lil'Log\", 'description': 'Diffusion models have demonstrated strong results on image synthesis in past years. Now the research community has started working on a harder task—using it for video generation. The task itself is a superset of the image case, since an image is a video of 1 frame, and it is much more challenging because:\\n\\nIt has extra requirements on temporal consistency across frames in time, which naturally demands more world knowledge to be encoded into the model.\\nIn comparison to text or images, it is more difficult to collect large amounts of high-quality, high-dimensional video data, let along text-video pairs.\\n\\n\\n\\n🥑 Required Pre-read: Please make sure you have read the previous blog on “What are Diffusion Models?” for image generation before continue here.\\n', 'language': 'en'}, page_content='In the case of video generation, we need the diffusion model to run multiple steps of upsampling for extending video length or increasing the frame rate. This requires the capability of sampling a second video $\\\\mathbf{x}^b$ conditioned on the first $\\\\mathbf{x}^a$, $\\\\mathbf{x}^b \\\\sim p_\\\\theta(\\\\mathbf{x}^b \\\\vert \\\\mathbf{x}^a)$, where $\\\\mathbf{x}^b$ might be an autoregressive extension of $\\\\mathbf{x}^a$ or be the missing frames in-between for a video $\\\\mathbf{x}^a$ at a low frame rate.'), Document(id='2da3d7d1-a418-477b-9879-278a7f1e2cd5', metadata={'source': 'https://lilianweng.github.io/posts/2024-04-12-diffusion-video/', 'title': \"Diffusion Models for Video Generation | Lil'Log\", 'description': 'Diffusion models have demonstrated strong results on image synthesis in past years. Now the research community has started working on a harder task—using it for video generation. The task itself is a superset of the image case, since an image is a video of 1 frame, and it is much more challenging because:\\n\\nIt has extra requirements on temporal consistency across frames in time, which naturally demands more world knowledge to be encoded into the model.\\nIn comparison to text or images, it is more difficult to collect large amounts of high-quality, high-dimensional video data, let along text-video pairs.\\n\\n\\n\\n🥑 Required Pre-read: Please make sure you have read the previous blog on “What are Diffusion Models?” for image generation before continue here.\\n', 'language': 'en'}, page_content='[3] Bar-Tal et al. 2024 “Lumiere: A Space-Time Diffusion Model for Video Generation.”\\n[4] Brooks et al. “Video generation models as world simulators.” OpenAI Blog, 2024.\\n[5] Zhang et al. 2023 “ControlVideo: Training-free Controllable Text-to-Video Generation.”\\n[6] Khachatryan et al. 2023 “Text2Video-Zero: Text-to-image diffusion models are zero-shot video generators.”\\n[7] Ho, et al. 2022 “Imagen Video: High Definition Video Generation with Diffusion Models.”')], 'answer': \"Agent loops are not explicitly mentioned in the provided context about diffusion video generation, so let's focus on detailing the challenges involved in diffusion video generation based on the given information.\\n\\n### Challenges in Diffusion Video Generation\\n\\n1. **Complexity of Video Data**: Video generation is inherently more complex than image generation, as it involves creating a coherent sequence of frames over time rather than just a single frame. This requires maintaining both spatial and temporal coherence, which adds significant complexity to the task.\\n\\n2. **Upsampling Requirements**: The need to extend video length or increase frame rate requires sophisticated upsampling techniques. Specifically, this includes the ability to sample subsequent video segments conditioned on initial segments, maintaining the continuity and flow of motion throughout the video.\\n\\n3. **Autoregressive Extensions and Missing Frames**: The model should handle scenarios where it needs to predict potential future frames (autoregressive extensions) as well as interpolate missing frames to create smooth transitions in videos with low frame rates. This involves understanding the underlying dynamics and continuity of the scene depicted in the video.\\n\\n4. **Cascade of Diffusion Models**: As seen in approaches like Imagen Video, generating high-quality video often involves using a cascade of multiple diffusion models. Managing this cascade to ensure quality and efficiency is another challenge.\\n\\n5. **Sampling Efficiency**: Speeding up the sampling process without degrading the quality of the video output is a significant challenge. Techniques like progressive distillation are employed to reduce the number of necessary sampling steps, demanding careful optimization to balance performance with perceptual quality.\\n\\nOverall, diffusion video generation requires sophisticated modeling to address temporal dynamics, maintain visual coherence, efficiently handle high-dimensional data, and achieve high-quality output within practical time constraints.\"}\n",
      "\n",
      "🔍 Sub-questions:\n",
      "- 1. What are agent loops, and how do they function in video generation processes?\n",
      "- 2. What specific challenges are associated with diffusion methods in video generation?\n",
      "\n",
      "✅ Final Answer:\n",
      " Agent loops are not explicitly mentioned in the provided context about diffusion video generation, so let's focus on detailing the challenges involved in diffusion video generation based on the given information.\n",
      "\n",
      "### Challenges in Diffusion Video Generation\n",
      "\n",
      "1. **Complexity of Video Data**: Video generation is inherently more complex than image generation, as it involves creating a coherent sequence of frames over time rather than just a single frame. This requires maintaining both spatial and temporal coherence, which adds significant complexity to the task.\n",
      "\n",
      "2. **Upsampling Requirements**: The need to extend video length or increase frame rate requires sophisticated upsampling techniques. Specifically, this includes the ability to sample subsequent video segments conditioned on initial segments, maintaining the continuity and flow of motion throughout the video.\n",
      "\n",
      "3. **Autoregressive Extensions and Missing Frames**: The model should handle scenarios where it needs to predict potential future frames (autoregressive extensions) as well as interpolate missing frames to create smooth transitions in videos with low frame rates. This involves understanding the underlying dynamics and continuity of the scene depicted in the video.\n",
      "\n",
      "4. **Cascade of Diffusion Models**: As seen in approaches like Imagen Video, generating high-quality video often involves using a cascade of multiple diffusion models. Managing this cascade to ensure quality and efficiency is another challenge.\n",
      "\n",
      "5. **Sampling Efficiency**: Speeding up the sampling process without degrading the quality of the video output is a significant challenge. Techniques like progressive distillation are employed to reduce the number of necessary sampling steps, demanding careful optimization to balance performance with perceptual quality.\n",
      "\n",
      "Overall, diffusion video generation requires sophisticated modeling to address temporal dynamics, maintain visual coherence, efficiently handle high-dimensional data, and achieve high-quality output within practical time constraints.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5. Run the pipeline\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = \"Explain how agent loops work and what are the challenges in diffusion video generation?\"\n",
    "    initial_state = RAGState(question=user_query)\n",
    "    final_state = graph.invoke(initial_state)\n",
    "    print(final_state)\n",
    "\n",
    "    print(\"\\n🔍 Sub-questions:\")\n",
    "    for q in final_state['sub_questions']:\n",
    "        print(\"-\", q)\n",
    "\n",
    "    print(\"\\n✅ Final Answer:\\n\", final_state['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e763e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
