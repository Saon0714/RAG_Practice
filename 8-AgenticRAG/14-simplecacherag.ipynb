{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a86aa13",
   "metadata": {},
   "source": [
    "### What is Cache-Augmented Generation (CAG)?\n",
    "CAG is a retrieval-free approach that bypasses the usual step of querying external knowledge sources at inference time. Instead, it preloads relevant documents into the LLM's extended context window, precomputes the model’s key‑value (KV) cache, and reuses this during inference—so the model can generate responses without additional retrieval steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e6e537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x109ec0770>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x128821a30>, root_client=<openai.OpenAI object at 0x10629ecc0>, root_async_client=<openai.AsyncOpenAI object at 0x109f225d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm=init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d950ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cache variable\n",
    "Model_Cache={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48802156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def cache_model(query):\n",
    "    start_time=time.time()\n",
    "    if Model_Cache.get(query):  # We are just matching the query string\n",
    "        print(\"**CAche Hit**\")\n",
    "        end_time=time.time()\n",
    "        elapsed_time=end_time-start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed_time:.2f} seconds\")\n",
    "        return Model_Cache.get(query)\n",
    "    else:\n",
    "        print(\"***CACHE MISS – EXECUTING MODEL***\")\n",
    "        start_time = time.time()\n",
    "        response = llm.invoke(query)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed:.2f} seconds\")\n",
    "        Model_Cache[query] = response\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b3c6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 1.05 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C83P3t1w3BANA8T1wKMawHjcSScKx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--adb58d05-b25a-469b-94d6-92ea8706d869-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=cache_model(\"hi\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6407acf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C83P3t1w3BANA8T1wKMawHjcSScKx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--adb58d05-b25a-469b-94d6-92ea8706d869-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32188896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**CAche Hit**\n",
      "EXECUTION TIME: 0.00 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C83P3t1w3BANA8T1wKMawHjcSScKx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--adb58d05-b25a-469b-94d6-92ea8706d869-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=cache_model(\"hi\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d65ff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 9.34 seconds\n",
      "content='LangGraph is an innovative approach to harnessing the power of language models in order to facilitate better understanding, generation, and interaction with natural language. As language models have evolved, they have demonstrated remarkable capabilities in numerous applications, ranging from text generation to translation, sentiment analysis, and beyond. However, the integration of these models into user-friendly applications often presents challenges, which is where LangGraph comes into play.\\n\\nIn essence, LangGraph aims to create a conceptual framework and a user-friendly interface that allows developers and users to interact with and manipulate language models in a more intuitive manner. The key idea behind LangGraph is to treat language data as nodes and relationships within a graph, where each node represents specific concepts, phrases, or entities, and the edges between them signify their relationships or contextual associations. This graph-based representation of language helps in visualizing and understanding the intricate web of meanings and connections that exists within a given dataset.\\n\\nOne of the most significant advantages of LangGraph is its ability to facilitate complex queries and queries with multiple dimensions. Traditional text-based approaches often fall short when it comes to depth and complexity, whereas LangGraph’s visual representation allows users to formulate more sophisticated inquiries. For example, users can explore relationships between different entities, track the evolution of a particular concept over time, or even uncover hidden associations that may not be readily apparent in linear text formats.\\n\\nAnother critical feature of LangGraph is its potential for enhancing the transparency and interpretability of language models. With the increasing concerns surrounding the “black box” nature of AI, LangGraph provides a means for users to better understand the reasoning behind a language model’s output. By visualizing the connections and nodes that contribute to a particular outcome, users can gain insights into how decisions are made, leading to greater trust and collaboration between humans and machines.\\n\\nMoreover, LangGraph can be particularly beneficial in collaborative environments. Various stakeholders, such as content creators, editors, and data analysts, can work together more effectively by utilizing the graph model. They can discuss the relationships between different content pieces, come to a consensus on the direction of the narrative, and identify gaps in the existing material that need to be filled. This collaborative aspect not only improves the quality of the output but also fosters a more inclusive approach to content creation.\\n\\nFrom an educational standpoint, LangGraph can also play a pivotal role in aiding language learning and understanding. By providing learners with a graphical representation of language structures, vocabulary, and relationships, educators can create more engaging and interactive learning experiences. This visual aspect can help in reinforcing concepts and facilitating a deeper understanding of the nuances of language, which can be particularly beneficial for learners grappling with complex grammatical structures or rich vocabulary.\\n\\nIn summary, LangGraph represents a significant advancement in the realm of language processing and interaction. By leveraging graph-based frameworks to visualize and manipulate language data, it enhances the capabilities of language models and provides users with innovative tools for exploration, understanding, and collaboration. As the field continues to evolve, the integration of LangGraph into various applications will likely lead to more sophisticated and nuanced approaches to language processing, enhancing the overall user experience and broadening the horizons of what is possible within natural language understanding and generation.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 635, 'prompt_tokens': 18, 'total_tokens': 653, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C83PqwblHvEql2kRNsJaaq3ZBz7Xs', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--70e21e2f-2eda-4355-add7-0996eb51af9b-0' usage_metadata={'input_tokens': 18, 'output_tokens': 635, 'total_tokens': 653, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "query=\"can you give me 500 words on langgraph?\"\n",
    "response =cache_model(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37e3685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**CAche Hit**\n",
      "EXECUTION TIME: 0.00 seconds\n",
      "content='LangGraph is an innovative approach to harnessing the power of language models in order to facilitate better understanding, generation, and interaction with natural language. As language models have evolved, they have demonstrated remarkable capabilities in numerous applications, ranging from text generation to translation, sentiment analysis, and beyond. However, the integration of these models into user-friendly applications often presents challenges, which is where LangGraph comes into play.\\n\\nIn essence, LangGraph aims to create a conceptual framework and a user-friendly interface that allows developers and users to interact with and manipulate language models in a more intuitive manner. The key idea behind LangGraph is to treat language data as nodes and relationships within a graph, where each node represents specific concepts, phrases, or entities, and the edges between them signify their relationships or contextual associations. This graph-based representation of language helps in visualizing and understanding the intricate web of meanings and connections that exists within a given dataset.\\n\\nOne of the most significant advantages of LangGraph is its ability to facilitate complex queries and queries with multiple dimensions. Traditional text-based approaches often fall short when it comes to depth and complexity, whereas LangGraph’s visual representation allows users to formulate more sophisticated inquiries. For example, users can explore relationships between different entities, track the evolution of a particular concept over time, or even uncover hidden associations that may not be readily apparent in linear text formats.\\n\\nAnother critical feature of LangGraph is its potential for enhancing the transparency and interpretability of language models. With the increasing concerns surrounding the “black box” nature of AI, LangGraph provides a means for users to better understand the reasoning behind a language model’s output. By visualizing the connections and nodes that contribute to a particular outcome, users can gain insights into how decisions are made, leading to greater trust and collaboration between humans and machines.\\n\\nMoreover, LangGraph can be particularly beneficial in collaborative environments. Various stakeholders, such as content creators, editors, and data analysts, can work together more effectively by utilizing the graph model. They can discuss the relationships between different content pieces, come to a consensus on the direction of the narrative, and identify gaps in the existing material that need to be filled. This collaborative aspect not only improves the quality of the output but also fosters a more inclusive approach to content creation.\\n\\nFrom an educational standpoint, LangGraph can also play a pivotal role in aiding language learning and understanding. By providing learners with a graphical representation of language structures, vocabulary, and relationships, educators can create more engaging and interactive learning experiences. This visual aspect can help in reinforcing concepts and facilitating a deeper understanding of the nuances of language, which can be particularly beneficial for learners grappling with complex grammatical structures or rich vocabulary.\\n\\nIn summary, LangGraph represents a significant advancement in the realm of language processing and interaction. By leveraging graph-based frameworks to visualize and manipulate language data, it enhances the capabilities of language models and provides users with innovative tools for exploration, understanding, and collaboration. As the field continues to evolve, the integration of LangGraph into various applications will likely lead to more sophisticated and nuanced approaches to language processing, enhancing the overall user experience and broadening the horizons of what is possible within natural language understanding and generation.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 635, 'prompt_tokens': 18, 'total_tokens': 653, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C83PqwblHvEql2kRNsJaaq3ZBz7Xs', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--70e21e2f-2eda-4355-add7-0996eb51af9b-0' usage_metadata={'input_tokens': 18, 'output_tokens': 635, 'total_tokens': 653, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "query=\"can you give me 500 words on langgraph?\"\n",
    "response =cache_model(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50bc19f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 9.10 seconds\n",
      "content=\"LangGraph is an innovative framework designed to bridge the gap between natural language processing (NLP) and graph-based data representations. By leveraging the structure and semantic richness of graphs, LangGraph enhances the ability to analyze, interpret, and generate language in a manner that aligns more closely with human cognitive processes. This approach is particularly valuable in understanding and managing complex relationships within text data, thereby enabling a more nuanced interpretation of language.\\n\\nAt its core, LangGraph employs graphs to represent linguistic elements where nodes symbolize words or phrases, and edges represent the relationships between them. Such a representation can be particularly useful in various NLP tasks, such as word sense disambiguation, semantic similarity assessment, and knowledge extraction. By visualizing linguistic data as a network, LangGraph allows for the exploration of language in a more dynamic and interconnected way, compared to traditional linear text analysis.\\n\\nOne of the primary advantages of using a graph-based structure is its ability to capture the multi-faceted nature of language. Words are not used in isolation; their meanings often shift depending on context, usage, and relationships to other words. LangGraph adeptly models these relationships, enabling more sophisticated analyses such as entity recognition where the model can discern not just what entities are present but also how they are interrelated. This is particularly important in information retrieval systems and chatbots, where understanding context can significantly enhance the relevance of responses.\\n\\nMoreover, LangGraph can be integrated with various machine learning techniques, particularly those involving deep learning architectures. Through the use of nodes and edges, the framework can enhance embedding techniques, allowing for richer representations of words and phrases. Graph neural networks (GNNs), for instance, can be employed within LangGraph to propagate information across the graph, thereby refining the understanding of semantics in a way that considers both local and global contexts.\\n\\nIn practical applications, LangGraph shows promise in various domains such as social network analysis, sentiment analysis, and even creative writing. In the realm of social networks, for instance, it can analyze the language used in communication patterns to decipher group dynamics and influence. In sentiment analysis, the nuanced relationships captured in the graph can provide a more accurate representation of emotional nuances in text, surpassing the capabilities of traditional token-based approaches.\\n\\nFurthermore, LangGraph's versatility allows for adaptability across different languages and linguistic structures. The framework can accommodate the unique syntactic and semantic characteristics inherent to various languages, making it a valuable tool for global applications. By focusing on relationships rather than isolated words, LangGraph promotes a more universal understanding of language, breaking down barriers of linguistic diversity.\\n\\nDespite its advantages, implementing LangGraph does come with challenges. Constructing and maintaining a comprehensive and accurate graph can be resource-intensive, requiring significant computational power and storage. Additionally, ensuring the quality and relevance of the graph's connections may demand continual updates and refinements, particularly in rapidly changing language contexts such as slang or jargon.\\n\\nIn summary, LangGraph represents a forward-thinking approach in natural language processing that effectively utilizes graph theory to enhance the understanding of language. By capturing the intricate web of connections between words and phrases, it provides powerful tools for a variety of applications, from chatbots to sentiment analysis. As the field of NLP continues to evolve, frameworks like LangGraph will likely play a crucial role in advancing our ability to interact with and comprehend human language.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 663, 'prompt_tokens': 16, 'total_tokens': 679, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C83RCIkVEoYGbD15LbuOKwcpt787W', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--a0312d5d-a556-4a09-9a1f-adf0c0731918-0' usage_metadata={'input_tokens': 16, 'output_tokens': 663, 'total_tokens': 679, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "query=\"give me 500 words on langgraph?\" # Slightly different query so it will be a cache miss\n",
    "response =cache_model(query)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
