{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTroqVVzluHj"
      },
      "source": [
        "### ASTRADB VectorStore\n",
        "Go from app idea to production with the AI Platform with Astra DB, the ultra-low latency database made for AI and Langflow, the low-code RAG IDE\n",
        "https://www.datastax.com/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DdbGUdd-iacy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "os.environ[\"ASTRA_DB_API_ENDPOINT\"] = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
        "os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"] = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aWA0bZTOiaZh"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\",dimensions=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bmQZYiniaWV",
        "outputId": "52a27988-efcd-4ff5-c4db-eff3a7aeec1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x1072b49b0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x1072b4260>, model='text-embedding-3-small', dimensions=1024, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUmrERG9iaQd",
        "outputId": "78a22d62-27c9-4daa-83b8-659fd24fa6f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langchain_astradb.vectorstores.AstraDBVectorStore at 0x12e235010>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_astradb import AstraDBVectorStore\n",
        "vector_db=AstraDBVectorStore(\n",
        "    embedding=embeddings,\n",
        "    collection_name=\"astra_vector_langchain\",\n",
        "    namespace=None,\n",
        "\n",
        ")\n",
        "vector_db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwoez06VkPVP",
        "outputId": "c8132aa3-4564-4d73-c64d-0baf1406c723"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'tweet'}, page_content='I had chocolate chip pancakes and scrambled eggs for breakfast this morning.'),\n",
              " Document(metadata={'source': 'news'}, page_content='The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.'),\n",
              " Document(metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
              " Document(metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.'),\n",
              " Document(metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\"),\n",
              " Document(metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this review to find out.'),\n",
              " Document(metadata={'source': 'website'}, page_content='The top 10 soccer players in the world right now.'),\n",
              " Document(metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),\n",
              " Document(metadata={'source': 'news'}, page_content='The stock market is down 500 points today due to fears of a recession.'),\n",
              " Document(metadata={'source': 'tweet'}, page_content='I have a bad feeling I am going to get deleted :(')]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]\n",
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# text_splitter = RecursiveCharacterTextSplitter(\n",
        "#     chunk_size=50,\n",
        "#     chunk_overlap=10,\n",
        "#     length_function=len,\n",
        "# )\n",
        "\n",
        "# chunks = text_splitter.split_documents(documents)\n",
        "# chunks\n",
        "\n",
        "# We dont need to split the documents as they are already short enough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUz80mVRiaKt",
        "outputId": "98ce58e9-dc64-4529-aceb-d40a9fecdff0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['629bb200d2cc49d6b4be5eb22145eec6',\n",
              " '081d67d7d62a45e4b9a8ffb6945b5f88',\n",
              " 'ebf55badfa344c369d8637b5f6befa0c',\n",
              " 'a0968b384a694c15a9df3bc1278f2e90',\n",
              " 'b299250cd89c4b1fb338a96b1b0e2549',\n",
              " '000a130349e0486090344f633f03b53b',\n",
              " '06065dd7a8a24c6cabe4bf13531f508d',\n",
              " '35a782477ddf415eab00f5841f5f5909',\n",
              " 'cba10fd0a9c2409ca6fe6fb8176c864f',\n",
              " '8431929be68d4e5e91e2bb0f2380f193']"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_db.add_documents(documents=documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# vector_db.delete_collection()  # drops entire collection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pny4p7VdiaBw",
        "outputId": "55c9384c-cb31-40c7-e4ec-07342ed37426"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='081d67d7d62a45e4b9a8ffb6945b5f88', metadata={'source': 'news'}, page_content='The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.'),\n",
              " Document(id='cba10fd0a9c2409ca6fe6fb8176c864f', metadata={'source': 'news'}, page_content='The stock market is down 500 points today due to fears of a recession.'),\n",
              " Document(id='ebf55badfa344c369d8637b5f6befa0c', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
              " Document(id='8431929be68d4e5e91e2bb0f2380f193', metadata={'source': 'tweet'}, page_content='I have a bad feeling I am going to get deleted :(')]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### Search from Vector Store DB\n",
        "\n",
        "vector_db.similarity_search(\"What is the weather\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63rta9Sfk1vZ",
        "outputId": "7caeee76-a3cd-426d-e522-823f85fbe6d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* \"Building an exciting new project with LangChain - come check it out!\", metadata={'source': 'tweet'}\n",
            "* \"LangGraph is the best framework for building stateful, agentic applications!\", metadata={'source': 'tweet'}\n",
            "* \"Wow! That was an amazing movie. I can't wait to see it again.\", metadata={'source': 'tweet'}\n"
          ]
        }
      ],
      "source": [
        "results = vector_db.similarity_search(\n",
        "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
        "    k=3,\n",
        "    filter={\"source\": \"tweet\"},\n",
        ")\n",
        "for res in results:\n",
        "    print(f'* \"{res.page_content}\", metadata={res.metadata}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faIybJwglD1O",
        "outputId": "e25d5325-4961-4247-c448-83c788bb67fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* [SIM=0.72] \"Building an exciting new project with LangChain - come check it out!\", metadata={'source': 'tweet'}\n",
            "* [SIM=0.71] \"LangGraph is the best framework for building stateful, agentic applications!\", metadata={'source': 'tweet'}\n",
            "* [SIM=0.53] \"Wow! That was an amazing movie. I can't wait to see it again.\", metadata={'source': 'tweet'}\n"
          ]
        }
      ],
      "source": [
        "results = vector_db.similarity_search_with_score(\n",
        "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
        "    k=3,\n",
        "    filter={\"source\": \"tweet\"},\n",
        ")\n",
        "for res, score in results:\n",
        "    print(f'* [SIM={score:.2f}] \"{res.page_content}\", metadata={res.metadata}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6I81FX7lIKu",
        "outputId": "c1c3cfa3-aa2f-415b-bd58-3d58dfc57099"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='a0968b384a694c15a9df3bc1278f2e90', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### Retriever\n",
        "retriever=vector_db.as_retriever(\n",
        "  search_type=\"similarity_score_threshold\",\n",
        "    search_kwargs={\"k\": 1, \"score_threshold\": 0.5},\n",
        ")\n",
        "retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro267A9ulY82",
        "outputId": "c259395a-05d8-4534-e299-c7982f584fbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='a0968b384a694c15a9df3bc1278f2e90', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.'),\n",
              " Document(id='cba10fd0a9c2409ca6fe6fb8176c864f', metadata={'source': 'news'}, page_content='The stock market is down 500 points today due to fears of a recession.'),\n",
              " Document(id='081d67d7d62a45e4b9a8ffb6945b5f88', metadata={'source': 'news'}, page_content='The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.')]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### Retriever\n",
        "retriever=vector_db.as_retriever(\n",
        "  search_type=\"mmr\",\n",
        "    search_kwargs={\"k\": 3},\n",
        ")\n",
        "retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "l08jC-ublbqr"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm=ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C5Sd1wdbptmhmLnOHuWBcPZSe2XGQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6a2a1d5b-7d0c-431e-81c6-ca1e5366da5b-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"hi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x12e2a41a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1379ef980>, root_client=<openai.OpenAI object at 0x12e35fb90>, root_async_client=<openai.AsyncOpenAI object at 0x12e365880>, model_kwargs={}, openai_api_key=SecretStr('**********'))"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chat_models.base import init_chat_model\n",
        "\n",
        "llm=init_chat_model(\"openai:gpt-3.5-turbo\")\n",
        "#llm=init_chat_model(\"groq:\")\n",
        "llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modern RAG Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Retriever\n",
        "retriever=vector_db.as_retriever(\n",
        "  search_type=\"mmr\",\n",
        "    search_kwargs={\"k\": 3},\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='081d67d7d62a45e4b9a8ffb6945b5f88', metadata={'source': 'news'}, page_content='The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.'),\n",
              " Document(id='629bb200d2cc49d6b4be5eb22145eec6', metadata={'source': 'tweet'}, page_content='I had chocolate chip pancakes and scrambled eggs for breakfast this morning.'),\n",
              " Document(id='06065dd7a8a24c6cabe4bf13531f508d', metadata={'source': 'website'}, page_content='The top 10 soccer players in the world right now.')]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke(\"What is the weather forecast for tomorrow?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "## Create a prompt template\n",
        "system_prompt=\"\"\"You are an assistant for question-answering tasks. \n",
        "Use the following pieces of retrieved context to answer the question. \n",
        "If you don't know the answer, just say that you don't know. \n",
        "Use three sentences maximum and keep the answer concise.\n",
        "\n",
        "Context: {context}\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"human\", \"{input}\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
              "  context: RunnableLambda(format_docs)\n",
              "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
              "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
              "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x12e2a41a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1379ef980>, root_client=<openai.OpenAI object at 0x12e35fb90>, root_async_client=<openai.AsyncOpenAI object at 0x12e365880>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
              "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### Create a document chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "document_chain=create_stuff_documents_chain(llm,prompt)\n",
        "document_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RunnableBinding(bound=RunnableAssign(mapper={\n",
              "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
              "           | VectorStoreRetriever(tags=['AstraDBVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_astradb.vectorstores.AstraDBVectorStore object at 0x12e235010>, search_type='mmr', search_kwargs={'k': 3}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
              "})\n",
              "| RunnableAssign(mapper={\n",
              "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
              "              context: RunnableLambda(format_docs)\n",
              "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
              "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
              "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x12e2a41a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1379ef980>, root_client=<openai.OpenAI object at 0x12e35fb90>, root_async_client=<openai.AsyncOpenAI object at 0x12e365880>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
              "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
              "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### Create The Final RAG Chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "rag_chain=create_retrieval_chain(retriever,document_chain)\n",
        "rag_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input': 'What is the weather forecast for tomorrow?', 'context': [Document(id='081d67d7d62a45e4b9a8ffb6945b5f88', metadata={'source': 'news'}, page_content='The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.'), Document(id='629bb200d2cc49d6b4be5eb22145eec6', metadata={'source': 'tweet'}, page_content='I had chocolate chip pancakes and scrambled eggs for breakfast this morning.'), Document(id='06065dd7a8a24c6cabe4bf13531f508d', metadata={'source': 'website'}, page_content='The top 10 soccer players in the world right now.')], 'answer': 'The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.'}\n"
          ]
        }
      ],
      "source": [
        "response = rag_chain.invoke({\"input\": \"What is the weather forecast for tomorrow?\"})\n",
        "print(response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.'"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I don't know the weather forecast for yesterday.\""
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response2 = rag_chain.invoke({\"input\": \"What was the weather forecast for yesterday?\"})\n",
        "response2[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "RAG",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
